# ğŸ“Š Pipeline ETL - Stock Sentiment Analysis

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![Pandas](https://img.shields.io/badge/Pandas-2.0%2B-green)
![Plotly](https://img.shields.io/badge/Plotly-5.14%2B-purple)
![Status](https://img.shields.io/badge/Status-Completed-success)

---

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa un **pipeline ETL (Extract, Transform, Load)** completo para el anÃ¡lisis de sentimientos en noticias financieras. El sistema extrae datos de noticias del mercado de valores, los limpia y transforma, y genera visualizaciones interactivas para anÃ¡lisis exploratorio.

### ğŸ¯ Objetivos Alcanzados

âœ… **Pipeline ETL modular** con arquitectura Extract-Transform-Load  
âœ… **ExtracciÃ³n robusta** con detecciÃ³n automÃ¡tica de encoding  
âœ… **TransformaciÃ³n completa** con 7 operaciones de limpieza  
âœ… **Carga multi-formato** (CSV, Parquet, SQLite)  
âœ… **5 visualizaciones interactivas** en HTML con Plotly  
âœ… **Conclusiones basadas en datos reales** (4,101 registros, 2000-2016)  
âœ… **Git con 10+ commits** y 2 ramas (main, develop)  
âœ… **DocumentaciÃ³n completa** y profesional  

---

## ğŸ—‚ï¸ Estructura del Proyecto

```
par_2DB/
â”‚
â”œâ”€â”€ ğŸ“ Extract/                      # MÃ³dulo de ExtracciÃ³n
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ stock_extractor.py          # Extrae y valida datos CSV
â”‚
â”œâ”€â”€ ğŸ“ Transform/                    # MÃ³dulo de TransformaciÃ³n
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ stock_transformer.py        # Limpia y transforma datos
â”‚
â”œâ”€â”€ ğŸ“ Load/                         # MÃ³dulo de Carga
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ stock_loader.py             # Carga en mÃºltiples formatos
â”‚
â”œâ”€â”€ ğŸ“ data/                         # Datos procesados (auto-generados)
â”‚   â”œâ”€â”€ stock_senti_clean.csv       # CSV limpio (7.4 MB)
â”‚   â”œâ”€â”€ stock_senti_clean.parquet   # Parquet comprimido (5.6 MB)
â”‚   â””â”€â”€ stock_senti_clean.db        # SQLite con Ã­ndices (10.1 MB)
â”‚
â”œâ”€â”€ ğŸ“„ main.py                       # Pipeline ETL completo
â”œâ”€â”€ ğŸ“„ generate_analysis.py         # Genera visualizaciones HTML
â”œâ”€â”€ ğŸ“„ analysis_report.html         # Reporte interactivo (resultado final)
â”œâ”€â”€ ğŸ“„ stock_senti_analysis.csv     # Dataset original (fuente)
â”œâ”€â”€ ğŸ“„ requirements.txt             # Dependencias del proyecto
â”œâ”€â”€ ğŸ“„ .gitignore                   # Archivos ignorados por Git
â””â”€â”€ ğŸ“„ README.md                    # Esta documentaciÃ³n
```

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos

- **Python 3.10+** (recomendado)
- **pip** (gestor de paquetes)
- **Git** (control de versiones)

### InstalaciÃ³n RÃ¡pida

```bash
# 1. Clonar el repositorio
git clone <URL_DEL_REPOSITORIO>
cd par_2DB

# 2. Crear entorno virtual (recomendado)
python -m venv venv

# Windows
.\venv\Scripts\Activate.ps1

# Linux/Mac
source venv/bin/activate

# 3. Instalar dependencias
pip install -r requirements.txt
```

### Dependencias Principales

```
pandas>=2.0.0          # Procesamiento de datos
numpy>=1.24.0          # Operaciones numÃ©ricas
plotly>=5.14.0         # Visualizaciones interactivas
matplotlib>=3.7.0      # GrÃ¡ficos estÃ¡ticos
seaborn>=0.12.0        # Visualizaciones estadÃ­sticas
fastparquet>=2023.4.0  # Soporte Parquet
pyarrow>=12.0.0        # Engine Parquet alternativo
```

---

## ğŸ’» Uso del Proyecto

### Paso 1: Ejecutar Pipeline ETL

```bash
python main.py
```

**Este comando realiza:**

1. **Extract** ğŸ“‚
   - Lee `stock_senti_analysis.csv` (dataset original)
   - Detecta automÃ¡ticamente el encoding (latin-1)
   - Valida estructura y calidad de datos
   - **Salida:** 4,101 registros cargados

2. **Transform** ğŸ”„
   - Normaliza nombres de columnas
   - Convierte tipos de datos (datetime, int)
   - Maneja valores nulos
   - Elimina duplicados
   - Limpia y valida fechas
   - Normaliza valores de texto
   - Crea 6 features temporales: `year`, `month`, `day`, `day_of_week`, `quarter`, `sentiment`
   - **Salida:** Dataset limpio con 33 columnas

3. **Load** ğŸ’¾
   - Guarda en CSV limpio (7.4 MB)
   - Guarda en Parquet comprimido (5.6 MB - 24% mÃ¡s pequeÃ±o)
   - Guarda en SQLite con Ã­ndices en `date` y `label`
   - **Salida:** 3 archivos en carpeta `data/`

**Salida esperada:**

```
======================================================================
  ğŸš€ PIPELINE ETL - STOCK SENTIMENT ANALYSIS
======================================================================
â° Inicio: 2025-10-12 16:26:00

======================================================================
  ğŸ“‚ FASE 1: EXTRACT - ExtracciÃ³n de Datos
======================================================================
ğŸ“‚ Extrayendo datos desde: stock_senti_analysis.csv
âœ… Datos extraÃ­dos exitosamente con codificaciÃ³n latin-1
ğŸ“Š Dimensiones: 4101 filas Ã— 27 columnas

======================================================================
  ğŸ”„ FASE 2: TRANSFORM - TransformaciÃ³n de Datos
======================================================================
ğŸ“ Normalizando nombres de columnas...
   âœ“ Columnas normalizadas: 27 columnas
ğŸ”¢ Convirtiendo tipos de datos...
   âœ“ Columna 'date' convertida a datetime
   âœ“ Columna 'label' convertida a int
âœ¨ Creando features adicionales...
   âœ“ Features temporales creadas: year, month, day, day_of_week, quarter
   âœ“ Feature 'sentiment' creada

======================================================================
  ğŸ’¾ FASE 3: LOAD - Carga de Datos
======================================================================
ğŸ“„ Guardando en formato CSV...
   âœ“ CSV guardado: data\stock_senti_clean.csv (7562.12 KB)
ğŸ“¦ Guardando en formato Parquet...
   âœ“ Parquet guardado: data\stock_senti_clean.parquet (5742.67 KB)
ğŸ—„ï¸  Guardando en SQLite...
   âœ“ SQLite guardado: data\stock_senti_clean.db (10348.00 KB)

âœ… PIPELINE ETL COMPLETADO EXITOSAMENTE
======================================================================
```

---

### Paso 2: Generar AnÃ¡lisis Visual

```bash
python generate_analysis.py
```

**Este comando genera:**

- ğŸ“Š 5 visualizaciones interactivas con Plotly
- ğŸ“ˆ EstadÃ­sticas descriptivas del dataset
- ğŸ¯ Conclusiones basadas en datos reales
- ğŸ’¡ Insights y hallazgos principales
- ğŸŒ PÃ¡gina HTML standalone (no requiere servidor)

**Salida esperada:**

```
======================================================================
ğŸ¨ GENERANDO ANÃLISIS Y VISUALIZACIONES
======================================================================

ğŸ“‚ Cargando datos limpios...
âœ… 4,101 registros cargados

ğŸ“Š Generando estadÃ­sticas...
âœ… EstadÃ­sticas calculadas

ğŸ“ˆ Generando visualizaciones...
   1. DistribuciÃ³n de sentimientos...
   2. EvoluciÃ³n temporal...
   3. Heatmap mensual...
   4. Top palabras frecuentes...
   5. Sentimientos por dÃ­a...
âœ… 5 visualizaciones generadas

ğŸŒ Generando pÃ¡gina HTML...
âœ… PÃ¡gina HTML generada: analysis_report.html

======================================================================
âœ… ANÃLISIS COMPLETADO
======================================================================

ğŸ“Œ Para ver el anÃ¡lisis, abre: analysis_report.html
   Las grÃ¡ficas son interactivas (zoom, pan, hover, etc.)
```

---

### Paso 3: Ver Resultados

```bash
# Windows
Invoke-Item analysis_report.html

# Linux/Mac
open analysis_report.html

# O simplemente hacer doble clic en el archivo
```

---

## ğŸ”„ ExplicaciÃ³n del Pipeline ETL

### ğŸ“‚ FASE 1: Extract (ExtracciÃ³n)

**Archivo:** `Extract/stock_extractor.py`

**Clase:** `StockExtractor`

**Funcionalidades:**
- Lee archivos CSV con detecciÃ³n automÃ¡tica de encoding
- Soporta mÃºltiples codificaciones: UTF-8, Latin-1, ISO-8859-1, CP1252
- Valida estructura de datos
- Proporciona vista previa y estadÃ­sticas

**MÃ©todos principales:**
```python
extractor = StockExtractor('stock_senti_analysis.csv')
data = extractor.extract_data()           # Extrae datos
info = extractor.get_data_info()          # Info del dataset
preview = extractor.preview_data(rows=5)   # Vista previa
```

---

### ğŸ”„ FASE 2: Transform (TransformaciÃ³n)

**Archivo:** `Transform/stock_transformer.py`

**Clase:** `StockTransformer`

**7 Transformaciones aplicadas:**

1. **NormalizaciÃ³n de columnas**
   - Convierte nombres a minÃºsculas
   - Remueve espacios y caracteres especiales

2. **ConversiÃ³n de tipos**
   - `date` â†’ datetime64
   - `label` â†’ int (0=negativo, 1=positivo)
   - Columnas de texto â†’ string

3. **Manejo de nulos**
   - Identifica valores faltantes
   - Elimina o imputa segÃºn contexto

4. **EliminaciÃ³n de duplicados**
   - Detecta registros repetidos
   - Mantiene primera ocurrencia

5. **Limpieza de fechas**
   - Valida formato de fechas
   - Ordena cronolÃ³gicamente
   - Elimina fechas invÃ¡lidas

6. **NormalizaciÃ³n de valores**
   - Limpia espacios extra
   - Estandariza texto
   - Convierte a lowercase

7. **CreaciÃ³n de features**
   - `year` - AÃ±o (2000-2016)
   - `month` - Mes (1-12)
   - `day` - DÃ­a del mes (1-31)
   - `day_of_week` - DÃ­a de la semana (0=Lun, 6=Dom)
   - `quarter` - Trimestre (1-4)
   - `sentiment` - Etiqueta textual ("Positivo"/"Negativo")

**MÃ©todo principal:**
```python
transformer = StockTransformer(raw_data)
clean_data = transformer.transform()  # Aplica todas las transformaciones
```

---

### ğŸ’¾ FASE 3: Load (Carga)

**Archivo:** `Load/stock_loader.py`

**Clase:** `StockLoader`

**3 Formatos de salida:**

#### 1. CSV (7.4 MB)
```python
loader.load_to_csv(data, 'data/stock_senti_clean.csv')
```
- Formato universal
- FÃ¡cil de abrir en Excel
- Compatible con todas las herramientas

#### 2. Parquet (5.6 MB - 24% mÃ¡s pequeÃ±o)
```python
loader.load_to_parquet(data, 'data/stock_senti_clean.parquet')
```
- Formato columnar comprimido
- CompresiÃ³n Snappy
- Ideal para big data y Spark

#### 3. SQLite (10.1 MB con Ã­ndices)
```python
loader.load_to_sqlite(data, 'data/stock_senti_clean.db', 'stock_sentiment')
```
- Base de datos relacional
- Ãndices en `date` y `label`
- Consultas SQL optimizadas

**Ejemplo de consulta SQLite:**
```python
query = """
SELECT date, sentiment, top1 
FROM stock_sentiment 
WHERE sentiment = 'Positivo' 
  AND year = 2000
ORDER BY date DESC 
LIMIT 10
"""
result = loader.query_sqlite('data/stock_senti_clean.db', 'stock_sentiment', query)
```

---

## ğŸ“Š AnÃ¡lisis Exploratorio de Datos (EDA)

### Visualizaciones Generadas

El archivo `analysis_report.html` contiene **5 visualizaciones interactivas**:

#### 1. ğŸ¥§ DistribuciÃ³n de Sentimientos (Donut Chart)
- **Tipo:** GrÃ¡fica de dona interactiva
- **Datos:** ProporciÃ³n entre noticias positivas y negativas
- **Insight:** Dataset balanceado - 52.8% positivo, 47.2% negativo
- **InteracciÃ³n:** Hover para ver valores exactos

#### 2. ğŸ“ˆ EvoluciÃ³n Temporal Anual (Stacked Bar Chart)
- **Tipo:** GrÃ¡fica de barras apiladas
- **Datos:** EvoluciÃ³n del sentimiento aÃ±o por aÃ±o (2000-2016)
- **Insight:** Variabilidad en diferentes periodos econÃ³micos
- **InteracciÃ³n:** Click en leyenda para filtrar, zoom para detalles

#### 3. ğŸ”¥ Heatmap Mensual de Sentimientos
- **Tipo:** Mapa de calor
- **Datos:** DistribuciÃ³n de noticias positivas por mes y aÃ±o
- **Insight:** IdentificaciÃ³n de patrones estacionales
- **InteracciÃ³n:** Hover para ver valores exactos por celda

#### 4. ğŸ”¤ Top 15 Palabras MÃ¡s Frecuentes
- **Tipo:** GrÃ¡fica de barras horizontales
- **Datos:** TÃ©rminos mÃ¡s recurrentes en las 25 palabras clave por noticia
- **Insight:** "Corrections and clarifications" es la mÃ¡s frecuente (108 veces)
- **InteracciÃ³n:** Escala de color segÃºn frecuencia

#### 5. ğŸ“… Sentimientos por DÃ­a de la Semana
- **Tipo:** GrÃ¡fica de barras agrupadas
- **Datos:** DistribuciÃ³n semanal de sentimientos
- **Insight:** MiÃ©rcoles es el dÃ­a con mÃ¡s actividad noticiosa
- **InteracciÃ³n:** ComparaciÃ³n directa entre positivos y negativos

---

## ğŸ¯ Conclusiones del AnÃ¡lisis

### 1. Balance Equilibrado de Sentimientos

**Hallazgo:** El dataset muestra un balance casi perfecto entre noticias positivas (52.8%) y negativas (47.2%).

**Implicaciones:**
- âœ… Dataset ideal para entrenar modelos de clasificaciÃ³n
- âœ… No presenta sesgo hacia ningÃºn sentimiento
- âœ… Evita problemas de desbalanceo de clases
- âœ… Resultados mÃ¡s confiables en validaciÃ³n

### 2. Cobertura Temporal Extensa

**Hallazgo:** Datos que abarcan 17 aÃ±os (2000-2016) con 4,101 noticias.

**Implicaciones:**
- ğŸ“… Permite analizar diferentes ciclos econÃ³micos
- ğŸ“… Cubre eventos histÃ³ricos importantes:
  - Crisis punto-com (2000-2002)
  - Crisis financiera global (2008)
  - Post-crisis y recuperaciÃ³n (2010-2016)
- ğŸ“… Suficiente para identificar patrones de largo plazo

### 3. Patrones Temporales Identificados

**Hallazgos:**
- **DÃ­a mÃ¡s activo:** MiÃ©rcoles (mayor volumen de noticias)
- **VariaciÃ³n estacional:** ConcentraciÃ³n de noticias en ciertos meses
- **DistribuciÃ³n no uniforme:** Periodos con mayor actividad noticiosa

**Implicaciones:**
- ğŸ“Š Posible correlaciÃ³n con eventos econÃ³micos
- ğŸ“Š Patrones Ãºtiles para predicciÃ³n temporal
- ğŸ“Š Sugiere ciclos de atenciÃ³n mediÃ¡tica

### 4. Palabras Clave Relevantes

**Hallazgos:**
- Palabra mÃ¡s frecuente: "corrections and clarifications" (108 apariciones)
- Dominan tÃ©rminos editoriales y de rectificaciÃ³n
- Presencia de nombres propios y eventos especÃ­ficos

**Implicaciones:**
- ğŸ”¤ Dataset incluye meta-informaciÃ³n editorial
- ğŸ”¤ Refleja naturaleza del medio (correcciones frecuentes)
- ğŸ”¤ Ãštil para anÃ¡lisis de tÃ³picos y NLP

### 5. Calidad de Datos Ã“ptima

**MÃ©tricas de calidad:**
- âœ… **0 valores nulos** (100% completo)
- âœ… **0 duplicados** (datos Ãºnicos)
- âœ… **6 features temporales** creadas
- âœ… **Fechas validadas** y ordenadas
- âœ… **Tipos de datos correctos**

**Implicaciones:**
- ğŸ¯ Datos listos para machine learning
- ğŸ¯ No requiere preprocesamiento adicional
- ğŸ¯ Alta confiabilidad en anÃ¡lisis

---

## ğŸ“ˆ EstadÃ­sticas del Dataset

| MÃ©trica | Valor | DescripciÃ³n |
|---------|-------|-------------|
| **Total Registros** | 4,101 | Noticias Ãºnicas analizadas |
| **Periodo** | 2000-2016 | 17 aÃ±os de cobertura |
| **Positivos** | 2,166 (52.8%) | Noticias con sentimiento positivo |
| **Negativos** | 1,935 (47.2%) | Noticias con sentimiento negativo |
| **Columnas Originales** | 27 | Date, Label, Top1-Top25 |
| **Columnas Finales** | 33 | +6 features temporales |
| **Valores Nulos** | 0 | 100% datos completos |
| **Duplicados** | 0 | Datos Ãºnicos |
| **TamaÃ±o CSV** | 7.4 MB | Formato sin comprimir |
| **TamaÃ±o Parquet** | 5.6 MB | 24% mÃ¡s pequeÃ±o |
| **TamaÃ±o SQLite** | 10.1 MB | Con Ã­ndices optimizados |

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### Lenguaje y Framework
- **Python 3.10+** - Lenguaje principal
- **Pandas 2.0+** - ManipulaciÃ³n de datos
- **NumPy 1.24+** - Operaciones numÃ©ricas

### VisualizaciÃ³n
- **Plotly 5.14+** - GrÃ¡ficas interactivas
- **Matplotlib 3.7+** - GrÃ¡ficos estÃ¡ticos
- **Seaborn 0.12+** - Visualizaciones estadÃ­sticas

### Almacenamiento
- **FastParquet 2023.4+** - Formato Parquet
- **PyArrow 12.0+** - Engine alternativo Parquet
- **SQLite3** - Base de datos (built-in)

### Control de Versiones
- **Git** - Control de versiones distribuido
- **GitHub** - Hosting del repositorio

### MetodologÃ­a
- **Git Flow** - Desarrollo con ramas (main, develop)
- **Conventional Commits** - Mensajes de commit estandarizados

---

## ğŸ“ Archivos Generados

### DespuÃ©s de `python main.py`:

```
data/
â”œâ”€â”€ stock_senti_clean.csv         # CSV limpio (7.4 MB)
â”‚   â”œâ”€â”€ Formato: UTF-8
â”‚   â”œâ”€â”€ Separador: coma
â”‚   â””â”€â”€ Uso: Compatible con Excel, Pandas
â”‚
â”œâ”€â”€ stock_senti_clean.parquet     # Parquet comprimido (5.6 MB)
â”‚   â”œâ”€â”€ CompresiÃ³n: Snappy
â”‚   â”œâ”€â”€ Ahorro: 24% vs CSV
â”‚   â””â”€â”€ Uso: Big Data, Spark, Dask
â”‚
â””â”€â”€ stock_senti_clean.db          # SQLite (10.1 MB)
    â”œâ”€â”€ Tabla: stock_sentiment
    â”œâ”€â”€ Ãndices: date, label
    â””â”€â”€ Uso: Consultas SQL, anÃ¡lisis relacional
```

### DespuÃ©s de `python generate_analysis.py`:

```
analysis_report.html              # PÃ¡gina web interactiva (56 KB)
â”œâ”€â”€ 5 grÃ¡ficas Plotly interactivas
â”œâ”€â”€ EstadÃ­sticas descriptivas
â”œâ”€â”€ 5 conclusiones detalladas
â”œâ”€â”€ DiseÃ±o responsive
â””â”€â”€ 100% standalone (no requiere servidor)
```

---

## ğŸ“ Aprendizajes del Proyecto

### 1. Arquitectura ETL Modular
- SeparaciÃ³n de responsabilidades (Extract, Transform, Load)
- CÃ³digo reutilizable y mantenible
- FÃ¡cil de extender y modificar

### 2. Manejo de Datos
- DetecciÃ³n automÃ¡tica de encoding
- Transformaciones complejas con Pandas
- ValidaciÃ³n y limpieza de datos

### 3. MÃºltiples Formatos de Almacenamiento
- CSV para compatibilidad universal
- Parquet para eficiencia de almacenamiento
- SQLite para consultas SQL

### 4. VisualizaciÃ³n Interactiva
- Plotly para grÃ¡ficas dinÃ¡micas
- HTML standalone sin servidor
- DiseÃ±o responsive y profesional

### 5. Control de Versiones
- Git Flow con ramas main y develop
- Commits descriptivos y organizados
- Historial limpio y trazable

### 6. DocumentaciÃ³n
- README completo y profesional
- Comentarios en cÃ³digo
- Mensajes de salida informativos

---

## ğŸš€ Comandos RÃ¡pidos

```bash
# Ejecutar pipeline ETL completo
python main.py

# Generar anÃ¡lisis visual HTML
python generate_analysis.py

# Ver resultados (Windows)
Invoke-Item analysis_report.html

# Ver resultados (Linux/Mac)
open analysis_report.html

# Instalar dependencias
pip install -r requirements.txt

# Crear entorno virtual
python -m venv venv

# Activar entorno (Windows)
.\venv\Scripts\Activate.ps1

# Activar entorno (Linux/Mac)
source venv/bin/activate
```

---

## ğŸ”§ SoluciÃ³n de Problemas

### Error: "UnicodeDecodeError"
**SoluciÃ³n:** El script ahora detecta automÃ¡ticamente el encoding. Si persiste, verifica que `stock_senti_analysis.csv` estÃ© presente.

### Error: "ModuleNotFoundError"
**SoluciÃ³n:** Instala las dependencias:
```bash
pip install -r requirements.txt
```

### Error: "FileNotFoundError"
**SoluciÃ³n:** AsegÃºrate de ejecutar los comandos desde la carpeta `par_2DB`:
```bash
cd par_2DB
python main.py
```

### GrÃ¡ficas no se muestran en HTML
**SoluciÃ³n:** El archivo HTML requiere conexiÃ³n a internet para cargar la librerÃ­a Plotly. Si estÃ¡s offline, las grÃ¡ficas no se renderizarÃ¡n.

---

## ğŸ“ Requisitos Cumplidos

- âœ… **Pipeline ETL** completo en Python
- âœ… **Extract:** ExtracciÃ³n robusta con detecciÃ³n de encoding
- âœ… **Transform:** 7 transformaciones documentadas
- âœ… **Load:** 3 formatos de salida (CSV, Parquet, SQLite)
- âœ… **Visualizaciones:** 5 grÃ¡ficas interactivas (requisito: â‰¥5)
- âœ… **Git:** 10+ commits descriptivos (requisito: â‰¥5)
- âœ… **Ramas:** main y develop (requisito: â‰¥2)
- âœ… **DocumentaciÃ³n:** README completo y profesional
- âœ… **Conclusiones:** Basadas en datos reales con sustento estadÃ­stico

---

## ğŸ‘¨â€ğŸ’» Autor

**Cristian Vergara**
- GitHub: [@crisveg24](https://github.com/crisveg24)
- Proyecto: Pipeline ETL - Stock Sentiment Analysis
- Fecha: Octubre 2025

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Consulta el archivo `LICENSE` para mÃ¡s detalles.

---

## ğŸ™ Agradecimientos

- Dataset: Stock Sentiment Analysis
- TecnologÃ­as: Python, Pandas, Plotly
- MetodologÃ­a: ETL Pipeline, Git Flow

---

## ğŸ“ Contacto

Â¿Tienes preguntas o sugerencias?
- Abre un issue en GitHub
- EnvÃ­a un pull request
- Contacta al autor

---

**â­ Si este proyecto te fue Ãºtil, no olvides darle una estrella en GitHub!**

---

*Ãšltima actualizaciÃ³n: 12 de octubre de 2025*
