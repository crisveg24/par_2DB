# ğŸ“Š Pipeline ETL - Stock Sentiment Analysis

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![Pandas](https://img.shields.io/badge/Pandas-2.0%2B-green)
![Plotly](https://img.shields.io/badge/Plotly-5.14%2B-purple)
![Status](https://img.shields.io/badge/Status-Completed-success)

---

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa un **pipeline ETL (Extract, Transform, Load)** completo para el anÃ¡lisis de sentimientos en noticias financieras. El sistema extrae datos de noticias del mercado de valores, los limpia y transforma, y genera visualizaciones interactivas para anÃ¡lisis exploratorio.

### ğŸ¯ Objetivos Alcanzados

âœ… **Pipeline ETL modular** con arquitectura Extract-Transform-Load  
âœ… **ExtracciÃ³n robusta** con detecciÃ³n automÃ¡tica de encoding  
âœ… **TransformaciÃ³n completa** con 7 operaciones de limpieza  
âœ… **Carga multi-formato** (CSV, Parquet, SQLite)  
âœ… **5 visualizaciones interactivas** en HTML con Plotly  
âœ… **Conclusiones basadas en datos reales** (4,101 registros, 2000-2016)  
âœ… **Git con 10+ commits** y 2 ramas (main, develop)  
âœ… **DocumentaciÃ³n completa** y profesional  

---

## ğŸ—‚ï¸ Estructura del Proyecto

```
par_2DB/
â”‚
â”œâ”€â”€ ğŸ“ Extract/                      # MÃ³dulo de ExtracciÃ³n
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ stock_extractor.py          # Extrae y valida datos CSV
â”‚
â”œâ”€â”€ ğŸ“ Transform/                    # MÃ³dulo de TransformaciÃ³n
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ stock_transformer.py        # Limpia y transforma datos
â”‚
â”œâ”€â”€ ğŸ“ Load/                         # MÃ³dulo de Carga
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ stock_loader.py             # Carga en mÃºltiples formatos
â”‚
â”œâ”€â”€ ğŸ“ data/                         # Datos procesados (auto-generados)
â”‚   â”œâ”€â”€ stock_senti_clean.csv       # CSV limpio (7.4 MB)
â”‚   â”œâ”€â”€ stock_senti_clean.parquet   # Parquet comprimido (5.6 MB)
â”‚   â””â”€â”€ stock_senti_clean.db        # SQLite con Ã­ndices (10.1 MB)
â”‚
â”œâ”€â”€ ğŸ“„ main.py                       # Pipeline ETL completo
â”œâ”€â”€ ğŸ“„ generate_analysis.py         # Genera visualizaciones HTML
â”œâ”€â”€ ğŸ“„ analysis_report.html         # Reporte interactivo (resultado final)
â”œâ”€â”€ ğŸ“„ stock_senti_analysis.csv     # Dataset original (fuente)
â”œâ”€â”€ ğŸ“„ requirements.txt             # Dependencias del proyecto
â”œâ”€â”€ ğŸ“„ .gitignore                   # Archivos ignorados por Git
â””â”€â”€ ğŸ“„ README.md                    # Esta documentaciÃ³n
```

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos

- **Python 3.10+** (recomendado)
- **pip** (gestor de paquetes)
- **Git** (control de versiones)

### InstalaciÃ³n RÃ¡pida

```bash
# 1. Clonar el repositorio
git clone <URL_DEL_REPOSITORIO>
cd par_2DB

# 2. Crear entorno virtual (recomendado)
python -m venv venv

# Windows
.\venv\Scripts\Activate.ps1

# Linux/Mac
source venv/bin/activate

# 3. Instalar dependencias
pip install -r requirements.txt
```

### Dependencias Principales

```
pandas>=2.0.0          # Procesamiento de datos
numpy>=1.24.0          # Operaciones numÃ©ricas
plotly>=5.14.0         # Visualizaciones interactivas
matplotlib>=3.7.0      # GrÃ¡ficos estÃ¡ticos
seaborn>=0.12.0        # Visualizaciones estadÃ­sticas
fastparquet>=2023.4.0  # Soporte Parquet
pyarrow>=12.0.0        # Engine Parquet alternativo
```

---

## ğŸ’» Uso del Proyecto

### Ejecutar Pipeline ETL

```bash
python main.py
```

**Â¡Eso es todo!** El script automÃ¡ticamente:
1. âœ… Ejecuta el pipeline ETL completo
2. âœ… Genera todos los archivos (CSV, Parquet, SQLite, HTML)
3. âœ… Inicia un servidor HTTP automÃ¡ticamente
4. âœ… Abre el reporte en tu navegador

**En GitHub Codespaces:**
- VS Code mostrarÃ¡ una notificaciÃ³n de "Port disponible"
- Haz clic en "Open in Browser" 
- O copia la URL que aparece en la terminal

**Archivos generados:**
- `data/stock_senti_clean.csv`
- `data/stock_senti_clean.parquet`
- `data/stock_senti_clean.db`
- `reporte_analisis.html`

âš ï¸ **Nota:** MantÃ©n la terminal abierta mientras uses el reporte. Presiona `Ctrl+C` para detener el servidor.

---

### ğŸ’» QuÃ© Hace el Pipeline

1. **Extract** ğŸ“‚
   - Lee `stock_senti_analysis.csv` (dataset original)
   - Detecta automÃ¡ticamente el encoding (latin-1)
   - Valida estructura y calidad de datos
   - **Salida:** 4,101 registros cargados

2. **Transform** ğŸ”„
   - Normaliza nombres de columnas
   - Convierte tipos de datos (datetime, int)
   - Maneja valores nulos
   - Elimina duplicados
   - Limpia y valida fechas
   - Normaliza valores de texto
   - Crea 6 features temporales: `year`, `month`, `day`, `day_of_week`, `quarter`, `sentiment`
   - **Salida:** Dataset limpio con 33 columnas

3. **Load** ğŸ’¾
   - Guarda en CSV limpio (7.4 MB)
   - Guarda en Parquet comprimido (5.6 MB - 24% mÃ¡s pequeÃ±o)
   - Guarda en SQLite con Ã­ndices en `date` y `label`
   - **Salida:** 3 archivos en carpeta `data/`

**Salida esperada:**

```
======================================================================
  ğŸš€ PIPELINE ETL - STOCK SENTIMENT ANALYSIS
======================================================================
â° Inicio: 2025-10-12 16:26:00

======================================================================
  ğŸ“‚ FASE 1: EXTRACT - ExtracciÃ³n de Datos
======================================================================
ğŸ“‚ Extrayendo datos desde: stock_senti_analysis.csv
âœ… Datos extraÃ­dos exitosamente con codificaciÃ³n latin-1
ğŸ“Š Dimensiones: 4101 filas Ã— 27 columnas

======================================================================
  ğŸ”„ FASE 2: TRANSFORM - TransformaciÃ³n de Datos
======================================================================
ğŸ“ Normalizando nombres de columnas...
   âœ“ Columnas normalizadas: 27 columnas
ğŸ”¢ Convirtiendo tipos de datos...
   âœ“ Columna 'date' convertida a datetime
   âœ“ Columna 'label' convertida a int
âœ¨ Creando features adicionales...
   âœ“ Features temporales creadas: year, month, day, day_of_week, quarter
   âœ“ Feature 'sentiment' creada

======================================================================
  ğŸ’¾ FASE 3: LOAD - Carga de Datos
======================================================================
ğŸ“„ Guardando en formato CSV...
   âœ“ CSV guardado: data\stock_senti_clean.csv (7562.12 KB)
ğŸ“¦ Guardando en formato Parquet...
   âœ“ Parquet guardado: data\stock_senti_clean.parquet (5742.67 KB)
ğŸ—„ï¸  Guardando en SQLite...
   âœ“ SQLite guardado: data\stock_senti_clean.db (10348.00 KB)

âœ… PIPELINE ETL COMPLETADO EXITOSAMENTE
======================================================================
```

---

### Paso 2: Generar AnÃ¡lisis Visual

```bash
python generate_analysis.py
```

**Este comando genera:**

- ğŸ“Š 5 visualizaciones interactivas con Plotly
- ğŸ“ˆ EstadÃ­sticas descriptivas del dataset
- ğŸ¯ Conclusiones basadas en datos reales
- ğŸ’¡ Insights y hallazgos principales
- ğŸŒ PÃ¡gina HTML standalone (no requiere servidor)

**Salida esperada:**

```
======================================================================
ğŸ¨ GENERANDO ANÃLISIS Y VISUALIZACIONES
======================================================================

ğŸ“‚ Cargando datos limpios...
âœ… 4,101 registros cargados

ğŸ“Š Generando estadÃ­sticas...
âœ… EstadÃ­sticas calculadas

ğŸ“ˆ Generando visualizaciones...
   1. DistribuciÃ³n de sentimientos...
   2. EvoluciÃ³n temporal...
   3. Heatmap mensual...
   4. Top palabras frecuentes...
   5. Sentimientos por dÃ­a...
âœ… 5 visualizaciones generadas

ğŸŒ Generando pÃ¡gina HTML...
âœ… PÃ¡gina HTML generada: analysis_report.html

======================================================================
âœ… ANÃLISIS COMPLETADO
======================================================================

ğŸ“Œ Para ver el anÃ¡lisis, abre: analysis_report.html
   Las grÃ¡ficas son interactivas (zoom, pan, hover, etc.)
```

---

### Paso 3: Ver Resultados

```bash
# Windows
Invoke-Item analysis_report.html

# Linux/Mac
open analysis_report.html

# O simplemente hacer doble clic en el archivo
```

---

## ğŸ”„ ExplicaciÃ³n del Pipeline ETL

### ğŸ“‚ FASE 1: Extract (ExtracciÃ³n)

**Archivo:** `Extract/stock_extractor.py`

**Clase:** `StockExtractor`

**Funcionalidades:**
- Lee archivos CSV con detecciÃ³n automÃ¡tica de encoding
- Soporta mÃºltiples codificaciones: UTF-8, Latin-1, ISO-8859-1, CP1252
- Valida estructura de datos

---

## ğŸ“ Resumen RÃ¡pido

### Ejecutar en GitHub Codespaces o Local:

```bash
# Â¡Solo ejecuta esto!
python main.py
```

El script automÃ¡ticamente:
- âœ… Procesa todos los datos
- âœ… Genera visualizaciones
- âœ… Inicia servidor HTTP
- âœ… Abre el reporte en tu navegador

**En Codespaces:** Haz clic en "Open in Browser" cuando aparezca la notificaciÃ³n de puerto.

**Detener el servidor:** Presiona `Ctrl+C` en la terminal.

---

## ğŸ‘¨â€ğŸ’» Autor

**Cristian Vega**  
GitHub: [@crisveg24](https://github.com/crisveg24)  
Proyecto: [par_2DB](https://github.com/crisveg24/par_2DB)

---

**Â¡Disfruta del anÃ¡lisis! ğŸ“ŠğŸš€**
